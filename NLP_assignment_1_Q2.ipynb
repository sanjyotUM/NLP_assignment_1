{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the raw text into a dataframe\n",
    "\n",
    "def load_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        raw_text = f.read()\n",
    "\n",
    "    text_list = raw_text.strip().split(' ')  # Split single string into words\n",
    "\n",
    "    # Create a dataframe with unigram and bigrams in text\n",
    "    ngram = (\n",
    "        pd.DataFrame(data=text_list, columns=['unigram'])\n",
    "        .assign(unigram = lambda x: x['unigram'].str.strip())  # Remove whitespace and newline characters attached to words\n",
    "        .loc[lambda x: ~x['unigram'].isin([',', '.', \"'\", '\"', '`', '-', ':'])]  # Remove lone punctuation marks\n",
    "        .assign(second_word = lambda x: x['unigram'].shift(-1).fillna('EndOfDocument'))  # Get the next word in the same row\n",
    "        .assign(bigram = lambda x: x['unigram'].str.cat(x['second_word'], sep='::'))  # Join first and second word to make bigram\n",
    "        .drop(['second_word'], axis=1)\n",
    "    )\n",
    "    return ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the counts to generate helping terms in chi square and PMI calculation\n",
    "\n",
    "def preprocess(unicount, bicount):\n",
    "    df = bicount.copy()\n",
    "    \n",
    "    # Separate bigram\n",
    "    df['first'] = df['bigram'].str.split('::').str[0]\n",
    "    df['second'] = df['bigram'].str.split('::').str[1]\n",
    "    df = df.drop(['bigram'], axis=1)\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .merge(unicount, how='left', left_on='first', right_on='unigram')  # Get first word count\n",
    "        .drop(['unigram'], axis=1)\n",
    "        .rename(columns={'unicount': 'first_unigram_count'})\n",
    "        .merge(unicount, how='left', left_on='second', right_on='unigram')  # Get second word count\n",
    "        .drop(['unigram'], axis=1)\n",
    "        .rename(columns={'unicount': 'second_unigram_count'})\n",
    "        .assign(\n",
    "            first_and_second = lambda x: x['bicount'],  # First and second word bigram count\n",
    "            first_not_second = lambda x: x['first_unigram_count'] - x['bicount'],  # First word but not second word bigram count\n",
    "            not_first_second = lambda x: x['second_unigram_count'] - x['bicount'],  # Not first word but second word bigram count\n",
    "            not_first_not_second = lambda x: x['bicount'].sum() - x['first_unigram_count'] - x['second_unigram_count'] + x['bicount'],  # Not first and not second word bigram count\n",
    "            total_unigram = unicount['unicount'].sum(),\n",
    "            total_bigram = unicount['unicount'].sum() - 1\n",
    "        )\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chi_square_score(unicount, bicount):\n",
    "        \n",
    "    df = preprocess(unicount, bicount)\n",
    "\n",
    "    # Generate observed and expected frequencies, and calculate the respective terms\n",
    "    df['term11_obs'] = df['first_and_second']\n",
    "    df['term11_exp'] = ((df['first_unigram_count']/df['total_unigram']) * (df['second_unigram_count']/df['total_unigram']) * df['total_bigram'])\n",
    "    df['term11'] = np.square(df['term11_obs'] - df['term11_exp'])/df['term11_exp']\n",
    "    df = df.drop(['term11_obs', 'term11_exp'], axis=1)\n",
    "\n",
    "    df['term12_obs'] = df['not_first_second']\n",
    "    df['term12_exp'] = ((1 - df['first_unigram_count']/df['total_unigram']) * (df['second_unigram_count']/df['total_unigram']) * df['total_bigram'])\n",
    "    df['term12'] = np.square(df['term12_obs'] - df['term12_exp'])/df['term12_exp']\n",
    "    df = df.drop(['term12_obs', 'term12_exp'], axis=1)\n",
    "\n",
    "    df['term21_obs'] = df['first_not_second']\n",
    "    df['term21_exp'] = ((df['first_unigram_count']/df['total_unigram']) * (1 - df['second_unigram_count']/df['total_unigram']) * df['total_bigram'])\n",
    "    df['term21'] = np.square(df['term21_obs'] - df['term21_exp'])/df['term21_exp']\n",
    "    df = df.drop(['term21_obs', 'term21_exp'], axis=1)\n",
    "\n",
    "    df['term22_obs'] = df['not_first_not_second']\n",
    "    df['term22_exp'] = ((1 - df['first_unigram_count']/df['total_unigram']) * (1 - df['second_unigram_count']/df['total_unigram']) * df['total_bigram'])\n",
    "    df['term22'] = np.square(df['term22_obs'] - df['term22_exp'])/df['term22_exp']\n",
    "    df = df.drop(['term22_obs', 'term22_exp'], axis=1)\n",
    "\n",
    "    df['chi-square'] = df['term11'] + df['term12'] + df['term21'] + df['term22']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pmi_score(unicount, bicount):\n",
    "    df = preprocess(unicount, bicount)\n",
    "    \n",
    "    # Get probabilities and calculate PMI\n",
    "    df['P_w1w2'] = (df['first_and_second']/df['total_bigram'])\n",
    "    df['P_w1'] = (df['first_unigram_count']/df['total_unigram'])\n",
    "    df['P_w2'] = (df['second_unigram_count']/df['total_unigram'])\n",
    "    df['PMI'] = np.log2(df['P_w1w2']/(df['P_w1'] * df['P_w2']))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_asked_score(unicount, bicount, measure):\n",
    "    if measure == 'chi-square':\n",
    "        return get_chi_square_score(unicount, bicount)\n",
    "    elif measure == 'PMI':\n",
    "        return get_pmi_score(unicount, bicount)\n",
    "    else:\n",
    "        print(\"Invalid option for measure, choose 'chi-square' or 'PMI'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Script\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Collocations'\n",
    "measure = 'chi-square'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = load_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unigram</th>\n",
       "      <th>bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>It</td>\n",
       "      <td>It::is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>is::this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>this</td>\n",
       "      <td>this::adapting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>adapting</td>\n",
       "      <td>adapting::of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>of</td>\n",
       "      <td>of::absurd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unigram          bigram\n",
       "0        It          It::is\n",
       "1        is        is::this\n",
       "2      this  this::adapting\n",
       "3  adapting    adapting::of\n",
       "4        of      of::absurd"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts of unigrams and bigrams\n",
    "\n",
    "unigram_count = (\n",
    "    ngram\n",
    "    .groupby(by=['unigram'])\n",
    "    .agg({'unigram': 'count'})\n",
    "    .rename(columns={'unigram': 'unicount'})\n",
    "    .reset_index()\n",
    "    .sort_values(by='unicount', ascending=False)\n",
    ")\n",
    "\n",
    "bigram_count = (\n",
    "    ngram.groupby(by=['bigram'])\n",
    "    .agg({'bigram': 'count'})\n",
    "    .rename(columns={'bigram': 'bicount'})\n",
    "    .reset_index()\n",
    "    .sort_values(by='bicount', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_asked_score(unigram_count, bigram_count, measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi-square score:\n",
      "\n",
      "first           second   \n",
      "whooping        cough        430865.000005\n",
      "Hang            Seng         430865.000005\n",
      "Bare-Faced      Messiah      430865.000005\n",
      "Aga             Khan         430865.000005\n",
      "COMMERCIAL      PAPER        430865.000005\n",
      "Learning        Materials    430865.000005\n",
      "Roederer        Cristal      430865.000005\n",
      "Palo            Alto         430865.000005\n",
      "on-again        off-again    430865.000005\n",
      "PRECIOUS        METALS       430865.000005\n",
      "gon             na           430865.000005\n",
      "Kuala           Lumpur       430865.000005\n",
      "Puerto          Rico         430865.000005\n",
      "Leche           Fresca       430865.000005\n",
      "Kohlberg        Kravis       430865.000005\n",
      "der             Heyden       430865.000005\n",
      "Chips           Ahoy         430865.000005\n",
      "intellectually  honest       430865.000005\n",
      "nondescript     two-story    430865.000005\n",
      "J.E.            Buster       430865.000005\n",
      "Name: chi-square, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('{} score:\\n'.format(measure))\n",
    "print(df.set_index(['first', 'second'])[measure].sort_values(ascending=False).head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
